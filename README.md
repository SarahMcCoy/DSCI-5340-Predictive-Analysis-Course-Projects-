# DSCI-5340-Predictive-Analysis-Course-Projects-

"Welcome to our GitHub repository showcasing a semesters worth of collaborative projects from DSCI 5340 Predictive Analysis. Throughout this course, we delved into advanced statistical forecasting and predictive modeling to tackle real-world scenarios. 

Each project explores a new topic or concept, providing hands-on experience in applying machine learning techniques such as feature extraction, feature engineering, and performance evaluation. We've also ventured into analyzing non-traditional data using specialized analytical techniques like support vector machines, text analytics, and neural networks.

The repository serves as a testament to my mastery of advanced analytics tools in R and our ability to solve complex data-driven business problems. Join me on this journey of discovery and innovation as we showcase our collective expertise in predictive analysis."

## Project Overview:

### Homework 1: 
we delved into time series analysis and forecasting techniques applied to electricity demand data. Through visual examination and decomposition methods, we gained insights into the underlying trend-cycle and seasonal patterns inherent in the data. Additionally, we explored the process of adjusting for seasonality to reveal underlying trends, and investigated the impact of outliers on the analysis, discerning how their presence can significantly influence forecasting accuracy and decision-making processes. 
### Homework 2: 
we immersed ourselves in the realm of predictive modeling using insurance data. Through hands-on exploration, we gained insights into the process of model fitting, evaluation, and forecasting. We learned how to construct regression models incorporating both linear trend and seasonal effects, conduct diagnostic analyses to assess model validity, and utilize forecasting techniques to anticipate future trends and uncertainties. 
### Homework 3:
We dived into the application of the k-nearest neighbors (k-NN) algorithm for classification tasks using the Universal Bank dataset. Through a series of tasks, we explored key concepts in machine learning, including data partitioning for training and validation, feature standardization, model tuning, and performance evaluation using confusion matrices. We gained practical experience in selecting optimal hyperparameters, such as the value of k, through validation techniques to enhance model accuracy. Additionally, we examined the importance of data splitting into training, validation, and test sets to assess model generalization and reliability. 
### Homework 4:
we delved into the realm of Support Vector Machines (SVM) for classification tasks, focusing on predicting the presence of heart disease in patients using a dataset containing various clinical features. Through a series of tasks, we explored key concepts in SVM algorithm implementation and hyperparameter tuning. We learned how to preprocess data, partition it into training and test sets, and build SVM models using both linear and grid search hyperparameter optimization methods. Additionally, we gained insights into resampling techniques, model evaluation using confusion matrices, and the impact of hyperparameters on model performance. 
